{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0c78ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:06.928767Z",
     "iopub.status.busy": "2025-04-02T20:53:06.928485Z",
     "iopub.status.idle": "2025-04-02T20:53:23.422617Z",
     "shell.execute_reply": "2025-04-02T20:53:23.421293Z"
    },
    "papermill": {
     "duration": 16.500099,
     "end_time": "2025-04-02T20:53:23.424427",
     "exception": false,
     "start_time": "2025-04-02T20:53:06.924328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93c5f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:23.431295Z",
     "iopub.status.busy": "2025-04-02T20:53:23.431054Z",
     "iopub.status.idle": "2025-04-02T20:53:47.705286Z",
     "shell.execute_reply": "2025-04-02T20:53:47.704248Z"
    },
    "papermill": {
     "duration": 24.279061,
     "end_time": "2025-04-02T20:53:47.706798",
     "exception": false,
     "start_time": "2025-04-02T20:53:23.427737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.empty_cache()\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from medpy.metric import binary\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f40f9b2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.714268Z",
     "iopub.status.busy": "2025-04-02T20:53:47.713708Z",
     "iopub.status.idle": "2025-04-02T20:53:47.723023Z",
     "shell.execute_reply": "2025-04-02T20:53:47.722361Z"
    },
    "papermill": {
     "duration": 0.014386,
     "end_time": "2025-04-02T20:53:47.724256",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.709870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def roi_mask_func(x):\n",
    "    t1ce, t2, flair = x[0], x[1], x[2]\n",
    "    flair_bin = flair > 0.7\n",
    "    t2_bin = t2 > 0.7\n",
    "    t1ce_bin = t1ce > 0.9\n",
    "    flair_t2_mask = np.logical_and(flair_bin, t2_bin)\n",
    "\n",
    "    from skimage.measure import label, regionprops\n",
    "    roi = np.zeros_like(t1ce_bin, dtype=bool)\n",
    "    labeled = label(t1ce_bin)\n",
    "    for region in regionprops(labeled):\n",
    "        if region.solidity > 0.7 and region.area > 500 and region.major_axis_length > 35:\n",
    "            tumor_candidate = labeled == region.label\n",
    "            overlap = np.logical_and(tumor_candidate, flair_t2_mask)\n",
    "            if np.sum(overlap) > 20:\n",
    "                roi = np.logical_or(roi, tumor_candidate)\n",
    "    return roi[None, :, :]\n",
    "\n",
    "\n",
    "class BrainPatchesDataset(Dataset):\n",
    "    def __init__(self, X_paths, y_paths, roi_mask_func=None):\n",
    "        self.X_paths = X_paths\n",
    "        self.y_paths = y_paths\n",
    "        self.roi_mask_func = roi_mask_func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Wczytaj pliki .npz\n",
    "        X_npz = np.load(self.X_paths[idx])\n",
    "        y_npz = np.load(self.y_paths[idx])\n",
    "\n",
    "        # Oryginalne dane: [4, H, W, D]\n",
    "        X = X_npz[\"X\"].astype(np.float32)\n",
    "        y = y_npz[\"y\"].astype(np.float32)  # [3, H, W, D]\n",
    "\n",
    "        # Wybieramy slice środkowy\n",
    "        z = X.shape[-1] // 2\n",
    "        X_slice = X[..., z]     # [4, H, W]\n",
    "        y_slice = y[..., z]     # [3, H, W]\n",
    "\n",
    "        # Z-score normalizacja kanał po kanale\n",
    "        X_zscore = (X_slice - X_slice.mean(axis=(1, 2), keepdims=True)) / \\\n",
    "                   (X_slice.std(axis=(1, 2), keepdims=True) + 1e-8)\n",
    "\n",
    "        # Połącz 4 oryginalne + 4 znormalizowane kanały → [8, H, W]\n",
    "        X_combined = np.concatenate([X_slice, X_zscore], axis=0)\n",
    "\n",
    "        # ROI (np. z FLAIR + T2 + T1ce), ale nie maskuje y\n",
    "        if self.roi_mask_func:\n",
    "            roi = self.roi_mask_func(X_slice[[1, 2, 3]])  # T1ce, T2, FLAIR\n",
    "        else:\n",
    "            roi = np.ones_like(X_combined[0:1])  # [1, H, W]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X_combined).float(),  # [8, H, W]\n",
    "            torch.tensor(y_slice).float(),     # [3, H, W]\n",
    "            torch.tensor(roi).float()          # [1, H, W]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cda2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.730667Z",
     "iopub.status.busy": "2025-04-02T20:53:47.730449Z",
     "iopub.status.idle": "2025-04-02T20:53:47.735706Z",
     "shell.execute_reply": "2025-04-02T20:53:47.735084Z"
    },
    "papermill": {
     "duration": 0.009685,
     "end_time": "2025-04-02T20:53:47.736797",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.727112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DistanceWiseAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature_map, expected_mask):\n",
    "        B, C, H, W = feature_map.shape\n",
    "        attn = torch.zeros((B, 1, H, W), device=feature_map.device)\n",
    "        for b in range(B):\n",
    "            mask = expected_mask[b, 0] > 0\n",
    "            if mask.sum() == 0: continue\n",
    "            coords = mask.nonzero(as_tuple=False).float()\n",
    "            yc, xc = coords.mean(dim=0)\n",
    "            y = torch.arange(H, device=feature_map.device).view(H, 1).repeat(1, W)\n",
    "            x = torch.arange(W, device=feature_map.device).view(1, W).repeat(H, 1)\n",
    "            dist = torch.sqrt((x - xc)**2 + (y - yc)**2) / H\n",
    "            attn[b, 0] = (1.0 - dist).clamp(0, 1)\n",
    "        return feature_map * attn.repeat(1, C, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15391799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.742718Z",
     "iopub.status.busy": "2025-04-02T20:53:47.742519Z",
     "iopub.status.idle": "2025-04-02T20:53:47.754500Z",
     "shell.execute_reply": "2025-04-02T20:53:47.753859Z"
    },
    "papermill": {
     "duration": 0.01629,
     "end_time": "2025-04-02T20:53:47.755710",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.739420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class GlobalPath(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=32):\n",
    "        super().__init__()\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.proj = nn.Linear(128, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, local_dim, global_dim, fusion_dim):\n",
    "        super().__init__()\n",
    "        self.local_proj = nn.Conv2d(local_dim, fusion_dim, kernel_size=1)\n",
    "        self.global_proj = nn.Linear(global_dim, fusion_dim)\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(fusion_dim, fusion_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(fusion_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, local_feat, global_feat):\n",
    "        B, C, H, W = local_feat.shape\n",
    "        local = self.local_proj(local_feat)\n",
    "        global_ = self.global_proj(global_feat).unsqueeze(2).unsqueeze(3)\n",
    "        global_ = global_.expand(-1, -1, H, W)\n",
    "        fused = self.fusion(local * global_)\n",
    "        return fused\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 2, out_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)\n",
    "\n",
    "\n",
    "class CascadeNet(nn.Module):\n",
    "    def __init__(self, in_channels=8, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.local_path = nn.Sequential(\n",
    "            ConvBlock(in_channels, 32),\n",
    "            ConvBlock(32, 64),\n",
    "            ConvBlock(64, 128)\n",
    "        )\n",
    "        self.global_path = GlobalPath(in_channels, out_channels=128)\n",
    "        self.att_fusion = AttentionFusion(local_dim=128, global_dim=128, fusion_dim=128)\n",
    "        self.distance_attn = DistanceWiseAttention()\n",
    "        self.decoder = Decoder(in_channels=128, out_channels=3)\n",
    "\n",
    "    def forward(self, x, roi):\n",
    "        local = self.local_path(x)\n",
    "        global_ = self.global_path(x)\n",
    "        fused = self.att_fusion(local, global_)\n",
    "        fused = self.distance_attn(fused, roi)\n",
    "        out = self.decoder(fused)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a42643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.761663Z",
     "iopub.status.busy": "2025-04-02T20:53:47.761462Z",
     "iopub.status.idle": "2025-04-02T20:53:47.765112Z",
     "shell.execute_reply": "2025-04-02T20:53:47.764516Z"
    },
    "papermill": {
     "duration": 0.007813,
     "end_time": "2025-04-02T20:53:47.766138",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.758325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_score(pred, target, eps=1e-6):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    return [(2 * (pred[:, i] * target[:, i]).sum() + eps) /\n",
    "            ((pred[:, i] + target[:, i]).sum() + eps) for i in range(target.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcb0fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.771987Z",
     "iopub.status.busy": "2025-04-02T20:53:47.771766Z",
     "iopub.status.idle": "2025-04-02T20:53:47.777151Z",
     "shell.execute_reply": "2025-04-02T20:53:47.776412Z"
    },
    "papermill": {
     "duration": 0.009517,
     "end_time": "2025-04-02T20:53:47.778272",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.768755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001, mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif self._is_improvement(current_score):\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Metric improved: {self.best_score:.5f} → {current_score:.5f}\")\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"⏳ No improvement: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def _is_improvement(self, score):\n",
    "        if self.mode == 'max':\n",
    "            return score > self.best_score + self.min_delta\n",
    "        elif self.mode == 'min':\n",
    "            return score < self.best_score - self.min_delta\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'max' or 'min'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4020144b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.784312Z",
     "iopub.status.busy": "2025-04-02T20:53:47.784105Z",
     "iopub.status.idle": "2025-04-02T20:53:47.799314Z",
     "shell.execute_reply": "2025-04-02T20:53:47.798740Z"
    },
    "papermill": {
     "duration": 0.019669,
     "end_time": "2025-04-02T20:53:47.800545",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.780876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, criterion, device, epochs=40, save_path=\"/kaggle/working\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path, \"pred_masks\"), exist_ok=True)\n",
    "    run_name = f\"CascadeNet_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=os.path.join(save_path, \"logs\", run_name))\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001, mode='max', verbose=True)\n",
    "    best_dice = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        train_dice_scores = []\n",
    "\n",
    "        for x, y, roi in dataloaders['train']:\n",
    "            x, y, roi = x.to(device), y.to(device), roi.to(device)\n",
    "            target = torch.argmax(y, dim=1).long()  # [B, H, W]\n",
    "\n",
    "            outputs = model(x, roi)\n",
    "            loss = criterion(outputs, target)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            train_dice_scores.append([d.item() for d in dice_score(outputs, y)])\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(dataloaders['train'])\n",
    "        train_dice_mean = np.mean(train_dice_scores, axis=0)\n",
    "\n",
    "        # ======= VALIDATION ========\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_dice_scores = []\n",
    "        val_hd = []\n",
    "        val_precision, val_recall, val_spec = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y, roi in dataloaders['val']:\n",
    "                x, y, roi = x.to(device), y.to(device), roi.to(device)\n",
    "                target = torch.argmax(y, dim=1).long()\n",
    "\n",
    "                outputs = model(x, roi)\n",
    "                loss = criterion(outputs, target)\n",
    "                val_loss += loss.item()\n",
    "                val_dice_scores.append([d.item() for d in dice_score(outputs, y)])\n",
    "\n",
    "                # Precision/Recall/Specificity\n",
    "                pred_bin = torch.softmax(outputs, dim=1) > 0.5\n",
    "                for i in range(y.shape[1]):\n",
    "                    p = pred_bin[:, i]\n",
    "                    t = y[:, i].bool()\n",
    "                    TP = (p & t).sum().item()\n",
    "                    FP = (p & ~t).sum().item()\n",
    "                    FN = (~p & t).sum().item()\n",
    "                    TN = (~p & ~t).sum().item()\n",
    "                    val_precision.append(TP / (TP + FP + 1e-6))\n",
    "                    val_recall.append(TP / (TP + FN + 1e-6))\n",
    "                    val_spec.append(TN / (TN + FP + 1e-6))\n",
    "\n",
    "\n",
    "                # Hausdorff 95\n",
    "                pred_np = (pred_bin.cpu().numpy()).astype(np.uint8)\n",
    "                y_np = y.cpu().numpy().astype(np.uint8)\n",
    "                hd_list = []\n",
    "                for i in range(y.shape[1]):\n",
    "                    try:\n",
    "                        hd = binary.hd95(pred_np[:, i], y_np[:, i])\n",
    "                    except:\n",
    "                        hd = np.nan\n",
    "                    hd_list.append(hd)\n",
    "                val_hd.append(hd_list)\n",
    "\n",
    "        val_dice_mean = np.mean(val_dice_scores, axis=0)\n",
    "        val_dice_avg = np.mean(val_dice_mean)\n",
    "        hd_mean = np.nanmean(val_hd, axis=0)\n",
    "        prec_mean = np.mean(np.array(val_precision).reshape(-1, 3), axis=0)\n",
    "        rec_mean = np.mean(np.array(val_recall).reshape(-1, 3), axis=0)\n",
    "        spec_mean = np.mean(np.array(val_spec).reshape(-1, 3), axis=0)\n",
    "\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Dice Avg: {val_dice_avg:.4f}\")\n",
    "        print(f\"Val Dice: WT={val_dice_mean[0]:.4f}, TC={val_dice_mean[1]:.4f}, EC={val_dice_mean[2]:.4f}\")\n",
    "        print(f\"Val Precision: {prec_mean}, Recall: {rec_mean}, Specificity: {spec_mean}\")\n",
    "        print(f\"Hausdorff95: {hd_mean}\")\n",
    "\n",
    "        # TensorBoard log\n",
    "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss / len(dataloaders['val']), epoch)\n",
    "        writer.add_scalar(\"Dice/Val_Mean\", val_dice_avg, epoch)\n",
    "        for i, cls in enumerate([\"WT\", \"TC\", \"EC\"]):\n",
    "            writer.add_scalar(f\"Dice/Val_{cls}\", val_dice_mean[i], epoch)\n",
    "            writer.add_scalar(f\"Precision/Val_{cls}\", prec_mean[i], epoch)\n",
    "            writer.add_scalar(f\"Recall/Val_{cls}\", rec_mean[i], epoch)\n",
    "            writer.add_scalar(f\"Specificity/Val_{cls}\", spec_mean[i], epoch)\n",
    "            writer.add_scalar(f\"Hausdorff95/Val_{cls}\", hd_mean[i], epoch)\n",
    "\n",
    "        # Save last model\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"cascade_last_model.pth\"))\n",
    "\n",
    "        # Save best model + predicted masks\n",
    "        if val_dice_avg > best_dice:\n",
    "            best_dice = val_dice_avg\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, \"cascade_best_model.pth\"))\n",
    "            print(f\"✅ Best model saved (Val Dice Avg: {val_dice_avg:.4f})\")\n",
    "\n",
    "            # Save predicted masks\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, (x, _, roi) in enumerate(dataloaders['val']):\n",
    "                    x, roi = x.to(device), roi.to(device)\n",
    "                    outputs = model(x, roi)\n",
    "                    preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1).cpu().numpy()\n",
    "                    for j, pred in enumerate(preds):\n",
    "                        name = f\"val_{i * x.size(0) + j}\"\n",
    "                        np.save(os.path.join(save_path, \"pred_masks\", f\"{name}.npy\"), pred)\n",
    "\n",
    "        # EarlyStopping\n",
    "        early_stopping(val_dice_avg)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"⛔ Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    writer.close()\n",
    "    print(\"✅ Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29f7a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:53:47.806553Z",
     "iopub.status.busy": "2025-04-02T20:53:47.806315Z",
     "iopub.status.idle": "2025-04-02T22:14:02.370566Z",
     "shell.execute_reply": "2025-04-02T22:14:02.369468Z"
    },
    "papermill": {
     "duration": 4814.573951,
     "end_time": "2025-04-02T22:14:02.377089",
     "exception": false,
     "start_time": "2025-04-02T20:53:47.803138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs.\n",
      "\n",
      "Epoch 1/100\n",
      "Train Loss: 0.7421 | Val Dice Avg: 0.0908\n",
      "Val Dice: WT=0.1085, TC=0.0518, EC=0.1119\n",
      "Val Precision: [0.06068678 0.19563478 0.27530171], Recall: [0.98378675 0.04431727 0.18165256], Specificity: [0.00863501 0.99942782 0.99797314]\n",
      "Hausdorff95: [58.75606959 40.99220812 37.82341429]\n",
      "✅ Best model saved (Val Dice Avg: 0.0908)\n",
      "\n",
      "Epoch 2/100\n",
      "Train Loss: 0.3429 | Val Dice Avg: 0.1094\n",
      "Val Dice: WT=0.1082, TC=0.0691, EC=0.1510\n",
      "Val Precision: [0.05927296 0.17175187 0.26256501], Recall: [0.95862116 0.04932598 0.20976309], Specificity: [0.01068035 0.99932736 0.99663161]\n",
      "Hausdorff95: [58.78961356 43.02377433 39.00866201]\n",
      "✅ Best model saved (Val Dice Avg: 0.1094)\n",
      "✅ Metric improved: 0.09075 → 0.10945\n",
      "\n",
      "Epoch 3/100\n",
      "Train Loss: 0.1887 | Val Dice Avg: 0.1084\n",
      "Val Dice: WT=0.0937, TC=0.0861, EC=0.1454\n",
      "Val Precision: [0.04945314 0.121473   0.16714626], Recall: [0.78212319 0.13790883 0.24853344], Specificity: [0.03122804 0.99086463 0.98398535]\n",
      "Hausdorff95: [59.03371787 36.44548109 40.60402931]\n",
      "⏳ No improvement: 1/10\n",
      "\n",
      "Epoch 4/100\n",
      "Train Loss: 0.1628 | Val Dice Avg: 0.1175\n",
      "Val Dice: WT=0.1060, TC=0.0815, EC=0.1650\n",
      "Val Precision: [0.05766769 0.2025968  0.22905388], Recall: [0.92843555 0.06263821 0.2336621 ], Specificity: [0.01480898 0.99892603 0.99309338]\n",
      "Hausdorff95: [58.83360623 42.34224124 39.44718887]\n",
      "✅ Best model saved (Val Dice Avg: 0.1175)\n",
      "✅ Metric improved: 0.10945 → 0.11750\n",
      "\n",
      "Epoch 5/100\n",
      "Train Loss: 0.1592 | Val Dice Avg: 0.1279\n",
      "Val Dice: WT=0.1022, TC=0.1087, EC=0.1728\n",
      "Val Precision: [0.05501772 0.1493273  0.28775137], Recall: [0.88691113 0.15010648 0.19969637], Specificity: [0.01281756 0.99338121 0.99851787]\n",
      "Hausdorff95: [58.84294209 36.31938549 38.42095744]\n",
      "✅ Best model saved (Val Dice Avg: 0.1279)\n",
      "✅ Metric improved: 0.11750 → 0.12790\n",
      "\n",
      "Epoch 6/100\n",
      "Train Loss: 0.1585 | Val Dice Avg: 0.1256\n",
      "Val Dice: WT=0.1063, TC=0.0993, EC=0.1711\n",
      "Val Precision: [0.05728186 0.20054208 0.20696228], Recall: [0.9184823  0.09349503 0.24815401], Specificity: [0.01940563 0.9983887  0.98905073]\n",
      "Hausdorff95: [58.87341848 36.95302784 39.19263115]\n",
      "⏳ No improvement: 1/10\n",
      "\n",
      "Epoch 7/100\n",
      "Train Loss: 0.1581 | Val Dice Avg: 0.1166\n",
      "Val Dice: WT=0.1102, TC=0.0811, EC=0.1585\n",
      "Val Precision: [0.06022145 0.20409855 0.27552301], Recall: [0.9730994  0.06013836 0.18328028], Specificity: [0.01301865 0.99929756 0.99646234]\n",
      "Hausdorff95: [58.80164645 45.04747743 39.50072999]\n",
      "⏳ No improvement: 2/10\n",
      "\n",
      "Epoch 8/100\n",
      "Train Loss: 0.1577 | Val Dice Avg: 0.1151\n",
      "Val Dice: WT=0.0983, TC=0.1065, EC=0.1406\n",
      "Val Precision: [0.05260495 0.11784616 0.20167351], Recall: [0.8328477  0.202908   0.21122189], Specificity: [0.0328972  0.98670698 0.98617442]\n",
      "Hausdorff95: [59.01629686 38.01487153 43.45565606]\n",
      "⏳ No improvement: 3/10\n",
      "\n",
      "Epoch 9/100\n",
      "Train Loss: 0.1572 | Val Dice Avg: 0.1198\n",
      "Val Dice: WT=0.1120, TC=0.0851, EC=0.1623\n",
      "Val Precision: [0.06082582 0.21630857 0.31076547], Recall: [0.9904858  0.05160806 0.14831384], Specificity: [0.0062072  0.99958104 0.99928329]\n",
      "Hausdorff95: [58.73545685 41.42208894 41.2336093 ]\n",
      "⏳ No improvement: 4/10\n",
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 0.1570 | Val Dice Avg: 0.1173\n",
      "Val Dice: WT=0.0984, TC=0.1003, EC=0.1532\n",
      "Val Precision: [0.05250309 0.14170824 0.19454764], Recall: [0.83652051 0.13269671 0.24442726], Specificity: [0.02597735 0.9938528  0.98336223]\n",
      "Hausdorff95: [58.97057077 35.88744012 41.56239524]\n",
      "⏳ No improvement: 5/10\n",
      "\n",
      "Epoch 11/100\n",
      "Train Loss: 0.1566 | Val Dice Avg: 0.1236\n",
      "Val Dice: WT=0.1076, TC=0.0840, EC=0.1791\n",
      "Val Precision: [0.05804333 0.21731455 0.2367187 ], Recall: [0.93539536 0.05910523 0.2353409 ], Specificity: [0.01305483 0.99949272 0.99252369]\n",
      "Hausdorff95: [58.82251629 41.09922036 39.77799726]\n",
      "⏳ No improvement: 6/10\n",
      "\n",
      "Epoch 12/100\n",
      "Train Loss: 0.1564 | Val Dice Avg: 0.1321\n",
      "Val Dice: WT=0.1065, TC=0.1166, EC=0.1734\n",
      "Val Precision: [0.05746936 0.19307341 0.26611242], Recall: [0.92498384 0.13257919 0.21584085], Specificity: [0.01481639 0.99676711 0.99496667]\n",
      "Hausdorff95: [58.83997288 36.21721097 38.3488266 ]\n",
      "✅ Best model saved (Val Dice Avg: 0.1321)\n",
      "✅ Metric improved: 0.12790 → 0.13214\n",
      "\n",
      "Epoch 13/100\n",
      "Train Loss: 0.1564 | Val Dice Avg: 0.1297\n",
      "Val Dice: WT=0.1036, TC=0.1129, EC=0.1726\n",
      "Val Precision: [0.05595701 0.16679173 0.24668207], Recall: [0.8974781  0.14353353 0.22639168], Specificity: [0.01799048 0.99456406 0.99263415]\n",
      "Hausdorff95: [58.8789583  36.01232998 39.44864452]\n",
      "⏳ No improvement: 1/10\n",
      "\n",
      "Epoch 14/100\n",
      "Train Loss: 0.1560 | Val Dice Avg: 0.1159\n",
      "Val Dice: WT=0.1008, TC=0.0884, EC=0.1586\n",
      "Val Precision: [0.05438589 0.17378101 0.21174176], Recall: [0.86585599 0.10928471 0.23826054], Specificity: [0.02491599 0.99646275 0.98620696]\n",
      "Hausdorff95: [58.95133457 36.73118277 40.77835684]\n",
      "⏳ No improvement: 2/10\n",
      "\n",
      "Epoch 15/100\n",
      "Train Loss: 0.1555 | Val Dice Avg: 0.1317\n",
      "Val Dice: WT=0.1044, TC=0.1141, EC=0.1765\n",
      "Val Precision: [0.05638467 0.17014122 0.23091747], Recall: [0.90123383 0.15071928 0.2346286 ], Specificity: [0.0195711  0.99458505 0.99237989]\n",
      "Hausdorff95: [58.88322424 33.93254147 39.57008158]\n",
      "⏳ No improvement: 3/10\n",
      "\n",
      "Epoch 16/100\n",
      "Train Loss: 0.1552 | Val Dice Avg: 0.1300\n",
      "Val Dice: WT=0.1073, TC=0.1155, EC=0.1672\n",
      "Val Precision: [0.058236   0.19496002 0.29712632], Recall: [0.93784335 0.14990298 0.17450834], Specificity: [0.01294199 0.99567004 0.99822832]\n",
      "Hausdorff95: [58.81937508 36.35977459 40.41607003]\n",
      "⏳ No improvement: 4/10\n",
      "\n",
      "Epoch 17/100\n",
      "Train Loss: 0.1551 | Val Dice Avg: 0.1237\n",
      "Val Dice: WT=0.0993, TC=0.1052, EC=0.1665\n",
      "Val Precision: [0.05320241 0.14879595 0.22564648], Recall: [0.84673075 0.15847664 0.23304573], Specificity: [0.02340505 0.99094607 0.98978998]\n",
      "Hausdorff95: [58.94484271 35.19133758 40.44142567]\n",
      "⏳ No improvement: 5/10\n",
      "\n",
      "Epoch 18/100\n",
      "Train Loss: 0.1551 | Val Dice Avg: 0.1070\n",
      "Val Dice: WT=0.0947, TC=0.0783, EC=0.1480\n",
      "Val Precision: [0.05047144 0.15613672 0.15504182], Recall: [0.79969915 0.07547641 0.25727425], Specificity: [0.02821941 0.99713251 0.97636985]\n",
      "Hausdorff95: [59.00265232 38.06977044 41.28727078]\n",
      "⏳ No improvement: 6/10\n",
      "\n",
      "Epoch 19/100\n",
      "Train Loss: 0.1546 | Val Dice Avg: 0.1264\n",
      "Val Dice: WT=0.1009, TC=0.1030, EC=0.1753\n",
      "Val Precision: [0.05431484 0.16837918 0.23804991], Recall: [0.87401043 0.10383824 0.22299709], Specificity: [0.01291386 0.99610948 0.99350522]\n",
      "Hausdorff95: [58.85553464 38.34002674 39.64797463]\n",
      "⏳ No improvement: 7/10\n",
      "\n",
      "Epoch 20/100\n",
      "Train Loss: 0.1543 | Val Dice Avg: 0.1223\n",
      "Val Dice: WT=0.1000, TC=0.1092, EC=0.1575\n",
      "Val Precision: [0.05361707 0.14046644 0.20570763], Recall: [0.85072884 0.15788191 0.23942879], Specificity: [0.03032515 0.99177182 0.98281191]\n",
      "Hausdorff95: [58.99446322 37.11876159 42.69173847]\n",
      "⏳ No improvement: 8/10\n",
      "\n",
      "Epoch 21/100\n",
      "Train Loss: 0.1544 | Val Dice Avg: 0.0946\n",
      "Val Dice: WT=0.1120, TC=0.0631, EC=0.1088\n",
      "Val Precision: [0.06092725 0.17809977 0.30675869], Recall: [0.99518564 0.0240251  0.07813023], Specificity: [0.00283021 0.99977155 0.99970512]\n",
      "Hausdorff95: [58.70490406 47.8317112  41.05195612]\n",
      "⏳ No improvement: 9/10\n",
      "\n",
      "Epoch 22/100\n",
      "Train Loss: 0.1542 | Val Dice Avg: 0.1070\n",
      "Val Dice: WT=0.1039, TC=0.0952, EC=0.1219\n",
      "Val Precision: [0.05593127 0.15447595 0.18699278], Recall: [0.89650744 0.13021739 0.15773188], Specificity: [0.0198538  0.99352024 0.99248622]\n",
      "Hausdorff95: [58.89186488 39.61070328 41.82399457]\n",
      "⏳ No improvement: 10/10\n",
      "⛔ Early stopping triggered at epoch 22\n",
      "✅ Training complete.\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"/kaggle/input/braintumor-dataset-patches\")\n",
    "\n",
    "train_X = sorted(list((data_dir / \"train\" / \"images\").glob(\"*.npz\")))\n",
    "train_y = sorted(list((data_dir / \"train\" / \"masks\").glob(\"*.npz\")))\n",
    "val_X = sorted(list((data_dir / \"val\" / \"images\").glob(\"*.npz\")))\n",
    "val_y = sorted(list((data_dir / \"val\" / \"masks\").glob(\"*.npz\")))\n",
    "\n",
    "train_ds = BrainPatchesDataset(train_X, train_y, roi_mask_func)\n",
    "val_ds = BrainPatchesDataset(val_X, val_y, roi_mask_func)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=2)\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "model = CascadeNet(in_channels=8, num_classes=3).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=100,\n",
    "    save_path=\"/kaggle/working/CascadeNet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7024024,
     "sourceId": 11242224,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4862.310131,
   "end_time": "2025-04-02T22:14:05.718243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-02T20:53:03.408112",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
